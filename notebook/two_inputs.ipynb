{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1d121aa-5301-4269-8260-4c77f7456cdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "print(torch.cuda.is_available())\n",
    "print(torch.cuda.current_device())\n",
    "gpu = torch.device('cuda:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89df4f4b-98bb-4754-b0cc-26eeda52cc92",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torchvision\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import datasets\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.transforms import ToTensor, Pad\n",
    "from torchvision.io import decode_image\n",
    "from torchinfo import summary as model_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c10081d-d2e5-482b-a1b8-b0193a4b095d",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(555)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d823280c-94ac-4323-9150-126451d255e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_to_500(img):\n",
    "    down = 500 - img.shape[1]\n",
    "    right = 500 - img.shape[2]\n",
    "    pad = Pad((0,0,right,down))\n",
    "    return pad(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79e47f42-3d9d-4feb-b665-76bcbc1fdf36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subset of VOC'2012 with object removed that CONTAIN ONLY 1 IMAGE\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, label_dir, img_dir, transform=None, target_transform=None):\n",
    "        self.bbox_label = pd.read_csv(label_dir)\n",
    "        self.img_dir = img_dir\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.bbox_label)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = os.path.join(self.img_dir, self.bbox_label.iloc[idx, 0])\n",
    "        image = decode_image(img_path).type(torch.float32)\n",
    "        label = torch.tensor([self.bbox_label.iloc[idx, i] for i in range(1,5)]).type(torch.float32)\n",
    "        if self.transform:\n",
    "            image = pad_to_500(self.transform(image))\n",
    "        if self.target_transform:\n",
    "            label = self.target_transform(label)\n",
    "        return image.to(gpu), label.to(gpu)\n",
    "\n",
    "    def get_imgname(self, idx):\n",
    "        return self.bbox_label.iloc[idx, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "232b0c6c-1e23-411c-967a-44e0fe3ae683",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_imgname(revoc, img):\n",
    "    for idx in range(len(revoc)):\n",
    "        ds_img, _ = revoc[idx]\n",
    "        if torch.equal(img, ds_img):\n",
    "            return revoc.get_imgname(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a23df03-fdf7-45e3-b561-aec8ea892098",
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet_preprocess = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "242b7ce6-9901-4843-8a05-88abe0ca0a10",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
